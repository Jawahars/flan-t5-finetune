{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU5UobcUGdCi"
      },
      "source": [
        "# Financial Document Analysis with Retrieval-Augmented Generation (RAG) and Finetuning\n",
        "\n",
        "This Jupyter Notebook demonstrates a complete workflow for building a Q&A system from financial reports using a Retrieval-Augmented Generation (RAG) architecture. We will process Kyndryl's annual reports, build a sophisticated retrieval system, and re-rank the results for higher accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S5eiZUuGdCi"
      },
      "source": [
        "### Part 1: Data Collection & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ScQpCIGdCi"
      },
      "source": [
        "**1.1: Obtain and Ingest Financial Statements**\n",
        "\n",
        "First, we'll install the necessary libraries for our project. Then, we will download the annual reports for the last two fiscal years from the provided URLs and store them locally. This step ensures we have the raw data ready for processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NCgjXbnpGfjG"
      },
      "outputs": [],
      "source": [
        "# !pip install \\\n",
        "#   accelerate>=1.10.0 \\\n",
        "#   datasets>=4.0.0 \\\n",
        "#   docling>=2.47.0 \\\n",
        "#   faiss-cpu>=1.12.0 \\\n",
        "#   huggingface-hub>=0.34.4 \\\n",
        "#   ipykernel>=6.30.1 \\\n",
        "#   pandas>=2.3.2 \\\n",
        "#   rank-bm25>=0.2.2 \\\n",
        "#   sentence-transformers>=5.1.0 \\\n",
        "#   sentencepiece>=0.2.1 \\\n",
        "#   tableformatter>=0.1.6 \\\n",
        "#   tabula>=1.0.5 \\\n",
        "#   torch>=2.8.0 \\\n",
        "#   transformers>=4.55.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j9DJvE_bGdCi"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from docling.document_converter import DocumentConverter\n",
        "_log = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVgS1aG-GdCj"
      },
      "source": [
        "# Download financial reports for KYNDRYL HOLDINGS, INC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B98bd6IqGdCj",
        "outputId": "5693e686-c0e9-4bcd-98f0-5421c49c5e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading annual_reports/0205a5a1-2f59-4ab7-b892-58615604423a.pdf...\n",
            "Downloading annual_reports/1488970a-672b-4caa-ad23-00c77e2b2434.pdf...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Create a directory to store the PDFs\n",
        "if not os.path.exists(\"annual_reports\"):\n",
        "    os.makedirs(\"annual_reports\")\n",
        "\n",
        "pdf_urls = [\n",
        "    \"https://investors.kyndryl.com/static-files/0205a5a1-2f59-4ab7-b892-58615604423a\",  # 2024 Annual Report\n",
        "    \"https://investors.kyndryl.com/static-files/1488970a-672b-4caa-ad23-00c77e2b2434\",  # 2023 Annual Report\n",
        "]\n",
        "pdf_paths = []\n",
        "for url in pdf_urls:\n",
        "    file_name = os.path.join(\"annual_reports\", url.split(\"/\")[-1]) + \".pdf\"\n",
        "    if not os.path.exists(file_name):\n",
        "        print(f\"Downloading {file_name}...\")\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(file_name, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "    else:\n",
        "        print(f\"{file_name} already exists.\")\n",
        "    pdf_paths.append(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC2ISh4YGdCj"
      },
      "source": [
        "**1.2: Convert Documents to Plain Text and Clean**\n",
        "\n",
        "We will use the `Docling` library to parse the downloaded PDF files and extract raw text. We will then apply a basic cleaning function to remove common artifacts like headers, footers, and extra whitespace, which are irrelevant for our Q&A task.\n",
        "\n",
        "The 2024 financial report contains the data for both the year 2024 and 2023."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nIp15nMGdCj",
        "outputId": "31038c68-effc-4e41-8b06-b4068266ccef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing annual_reports/0205a5a1-2f59-4ab7-b892-58615604423a.pdf from page 57 to 59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Table 0\n",
            "|    |                                                                      | Notes   | Year Ended.2024   | March 31,.2023   | Three Months Ended March 31,.2022   | Year Ended December 31,.2021   |\n",
            "|---:|:---------------------------------------------------------------------|:--------|:------------------|:-----------------|:------------------------------------|:-------------------------------|\n",
            "|  0 | Revenues * . . . . . . . . . . . . . . . . . . . . . . . . . . . . . | 3       | $ 16,052          | $ 17,026         | $ 4,431                             | $ 18,657                       |\n",
            "|  1 | Cost of services ** . . . . . . . . . . . . . . . . . . . . . . .    | 3       | $ 13,189          | $ 14,498         | $ 3,824                             | $ 16,550                       |\n",
            "|  2 | Selling, general and administrative expenses . .                     |         | 2,773             | 2,914            | 690                                 | 2,776                          |\n",
            "|  3 | Workforce rebalancing charges . . . . . . . . . . . . .              | 19      | 138               | 71               | -                                   | 39                             |\n",
            "|  4 | Transaction-related costs (benefits) . . . . . . . . . .             |         | (46)              | 264              | 58                                  | 627                            |\n",
            "|  5 | Impairment expense . . . . . . . . . . . . . . . . . . . . . .       | 10      | -                 | -                | -                                   | 469                            |\n",
            "|  6 | Interest expense . . . . . . . . . . . . . . . . . . . . . . . . . . | 11      | 122               | 94               | 21                                  | 64                             |\n",
            "|  7 | Other expense . . . . . . . . . . . . . . . . . . . . . . . . . . .  |         | 45                | 35               | 27                                  | 35                             |\n",
            "|  8 | Total costs and expenses . . . . . . . . . . . . . . . . . .         |         | $ 16,221          | $ 17,876         | $ 4,620                             | $ 20,560                       |\n",
            "|  9 | Income (loss) before income taxes . . . . . . . . .                  |         | $ (168)           | $ (851)          | $ (189)                             | $ (1,903)                      |\n",
            "| 10 | Provision for income taxes . . . . . . . . . . . . . . .             | 5       | $ 172             | $ 524            | $ 40                                | $ 402                          |\n",
            "| 11 | Net income (loss) . . . . . . . . . . . . . . . . . . . . . . . .    |         | $ (340)           | $ (1,374)        | $ (229)                             | $ (2,304)                      |\n",
            "| 12 | Basic earnings (loss) per share . . . . . . . . . . . . . .          | 6       | $ (1.48)          | $ (6.06)         | $ (1.02)                            | $ (10.28)                      |\n",
            "| 13 | Diluted earnings (loss) per share . . . . . . . . . . . .            |         | (1.48)            | (6.06)           | (1.02)                              | (10.28)                        |\n",
            "| 14 | Weighted-average basic shares outstanding . . .                      | 6       | 229.2             | 226.7            | 224.4                               | 224.1                          |\n",
            "| 15 | Weighted-average diluted shares outstanding. .                       |         | 229.2             | 226.7            | 224.4                               | 224.1                          |\n",
            "## Table 1\n",
            "|    |                                                                                                                                        | Year Ended.2024   | March 31,.2023   | Three Months Ended March 31,.2022   | Year Ended December 31,.2021   |\n",
            "|---:|:---------------------------------------------------------------------------------------------------------------------------------------|:------------------|:-----------------|:------------------------------------|:-------------------------------|\n",
            "|  0 | Net income (loss) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                          | $ (340)           | $ (1,374)        | $ (229)                             | $ (2,304)                      |\n",
            "|  1 | Other comprehensive income (loss), before tax:                                                                                         |                   |                  |                                     |                                |\n",
            "|  2 | Foreign currency translation adjustments:                                                                                              |                   |                  |                                     |                                |\n",
            "|  3 | Foreign currency translation adjustments . . . . . . . . . . . . . . . .                                                               | (36)              | (186)            | (51)                                | 194                            |\n",
            "|  4 | Unrealized losses on net investment hedges. . . . . . . . . . . . . . .                                                                | (11)              | -                | -                                   | -                              |\n",
            "|  5 | Total foreign currency translation adjustments. . . . . . . . . . . . . .                                                              | (47)              | (186)            | (51)                                | 194                            |\n",
            "|  6 | Unrealized gains (losses) on cash flow hedges:                                                                                         |                   |                  |                                     |                                |\n",
            "|  7 | Unrealized gains (losses) arising during the period . . . . . . . . .                                                                  | 22                | (4)              | 1                                   | 4                              |\n",
            "|  8 | Reclassification of (gains) losses to net income. . . . . . . . . . . .                                                                | (21)              | 2                | (1)                                 | (1)                            |\n",
            "|  9 | Total unrealized gains (losses) on cash flow hedges . . . . . . . . .                                                                  | 1                 | (3)              | -                                   | 3                              |\n",
            "| 10 | Retirement-related benefit plans:                                                                                                      |                   |                  |                                     |                                |\n",
            "| 11 | Prior service costs (credits) . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                  | (3)               | 4                | -                                   | 1                              |\n",
            "| 12 | Net gains (losses) arising during the period . . . . . . . . . . . . . . .                                                             | (56)              | 175              | 136                                 | 72                             |\n",
            "| 13 | Curtailments and settlements. . . . . . . . . . . . . . . . . . . . . . . . . . .                                                      | 10                | 10               | 4                                   | 3                              |\n",
            "| 14 | Amortization of prior service (credits) costs . . . . . . . . . . . . . .                                                              | 1                 | 1                | -                                   | -                              |\n",
            "| 15 | Amortization of net (gains) losses. . . . . . . . . . . . . . . . . . . . . . .                                                        | 5                 | 40               | 16                                  | 51                             |\n",
            "| 16 | Total retirement-related benefit plans . . . . . . . . . . . . . . . . . . . . .                                                       | (42)              | 229              | 156                                 | 127                            |\n",
            "| 17 | Other comprehensive income (loss), before tax . . . . . . . . . . . .                                                                  | (88)              | 40               | 105                                 | 324                            |\n",
            "| 18 | Income tax (expense) benefit related to items of other comprehensive income (loss) . . . . . . . . . . . . . . . . . . . . . . . . . . | 6                 | (14)             | (50)                                | (33)                           |\n",
            "| 19 | Other comprehensive income (loss), net of tax . . . . . . . . . . . . .                                                                | (82)              | 27               | 54                                  | 292                            |\n",
            "| 20 | Total comprehensive income (loss) . . . . . . . . . . . . . . . . . . . . . . .                                                        | $ (423)           | $ (1,347)        | $ (175)                             | $ (2,013)                      |\n",
            "## Table 2\n",
            "|    |                                                                                                                                                                                                                               | Notes   | 2024     | 2023     |\n",
            "|---:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:---------|:---------|\n",
            "|  0 | Assets:                                                                                                                                                                                                                       |         |          |          |\n",
            "|  1 | Current assets:                                                                                                                                                                                                               |         |          |          |\n",
            "|  2 | Cash and cash equivalents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                               |         | $ 1,553  | $ 1,847  |\n",
            "|  3 | Restricted cash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                         |         | 1        | 12       |\n",
            "|  4 | Accounts receivable (net of allowances for credit losses of $22 at March 31, 2024 and $32 at March 31, 2023). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . |         | 1,599    | 1,523    |\n",
            "|  5 | Deferred costs (current portion) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                | 3       | 1,081    | 1,070    |\n",
            "|  6 | Prepaid expenses and other current assets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                      |         | 514      | 510      |\n",
            "|  7 | Total current assets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                       |         | $ 4,747  | $ 4,963  |\n",
            "|  8 | Property and equipment, net . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                             |         |          |          |\n",
            "|  9 |                                                                                                                                                                                                                               | 8       | $ 2,674  | $ 2,779  |\n",
            "| 10 | Operating right-of-use assets, net . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                              | 9       | 864      | 964      |\n",
            "| 11 | Deferred costs (noncurrent portion). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                | 3       | 920      | 1,166    |\n",
            "| 12 | Deferred taxes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                    | 5       | 220      | 248      |\n",
            "| 13 | Goodwill . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                      | 10      | 805      | 812      |\n",
            "| 14 | Intangible assets, net. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                               | 10      | 188      | 171      |\n",
            "| 15 | Pension assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                              | 16      | 105      | 94       |\n",
            "| 16 | Other noncurrent assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                           |         | 67       | 267      |\n",
            "| 17 | Total assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                  |         | $ 10,590 | $ 11,464 |\n",
            "| 18 | Liabilities:                                                                                                                                                                                                                  |         |          |          |\n",
            "| 19 | Current liabilities:                                                                                                                                                                                                          |         |          |          |\n",
            "| 20 | Accounts payable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                                                |         | $ 1,408  | $ 1,774  |\n",
            "| 21 | . . . . . . . . . . . . . . . . . . Value-added tax and income tax liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                  |         | 327      | 347      |\n",
            "| 22 | Current portion of long-term debt. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                  | 11      | 126      | 110      |\n",
            "| 23 | Accrued compensation and benefits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                     |         | 609      | 533      |\n",
            "| 24 | Deferred income (current portion) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                   | 3       | 825      | 820      |\n",
            "| 25 | Operating lease liabilities (current portion). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                    | 9       | 285      | 316      |\n",
            "| 26 | Accrued contract costs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                             |         | 487      | 346      |\n",
            "| 27 | Other accrued expenses and liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                    | 12      | 521      | 624      |\n",
            "| 28 | Total current liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                       |         | $ 4,589  | $ 4,868  |\n",
            "| 29 | Long-term debt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                        | 11      | $ 3,112  | $ 3,111  |\n",
            "| 30 | Retirement and nonpension postretirement benefit obligations. . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                               | 16      | 500      | 504      |\n",
            "| 31 | . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                                                               | 3       | 314      | 362      |\n",
            "| 32 | Deferred income (noncurrent portion) . . . . Operating lease liabilities (noncurrent portion) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                       | 9       | 622      | 707      |\n",
            "| 33 | Other noncurrent liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                          | 12      | 332      | 450      |\n",
            "| 34 | Total liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                 |         | $ 9,468  | $ 10,002 |\n",
            "| 35 | Commitments and contingencies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                               | 13      |          |          |\n",
            "| 36 | Equity:                                                                                                                                                                                                                       |         |          |          |\n",
            "| 37 | Stockholders' equity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                      | 14      |          |          |\n",
            "| 38 | Common stock, par value $0.01 per share, and additional paid-in capital (shares authorized: 1,000.0; shares issued: March 31, 2024 - 233.7, March 31, 2023 - 229.6)                                                           |         | $ 4,524  | $ 4,428  |\n",
            "| 39 | Accumulated deficit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                         |         | (2,319)  | (1,978)  |\n",
            "| 40 | Treasury stock, at cost (shares: March 31, 2024 - 3.3, March 31, 2023 - 1.9). . . . . . . . . . . . . . .                                                                                                                     |         | (45)     | (23)     |\n",
            "| 41 | Accumulated other comprehensive income (loss) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                           |         | (1,145)  | (1,062)  |\n",
            "| 42 | Total stockholders' equity before non-controlling interests . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                           |         | $ 1,015  | $ 1,365  |\n",
            "| 43 | Non-controlling interests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                           |         | 107      | 97       |\n",
            "| 44 | Total equity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                  |         | $ 1,122  | $ 1,462  |\n",
            "| 45 | Total liabilities and equity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                        |         | $ 10,590 | $ 11,464 |\n"
          ]
        }
      ],
      "source": [
        "def parse_pdf(pdf_path, start, end):\n",
        "    print(f\"Parsing {pdf_path} from page {start} to {end}\")\n",
        "    res = []\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    input_doc_path = pdf_path\n",
        "    output_dir = Path(\"scratch\")\n",
        "\n",
        "    doc_converter = DocumentConverter()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    conv_res = doc_converter.convert(input_doc_path, page_range=(start, end))\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    doc_filename = conv_res.input.file.stem\n",
        "\n",
        "    # Export tables\n",
        "    for table_ix, table in enumerate(conv_res.document.tables):\n",
        "        table_df: pd.DataFrame = table.export_to_dataframe()\n",
        "        print(f\"## Table {table_ix}\")\n",
        "        res.append(table_df)\n",
        "        print(table_df.to_markdown())\n",
        "\n",
        "        # Save the table as csv\n",
        "        element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix + 1}.csv\"\n",
        "        _log.info(f\"Saving CSV table to {element_csv_filename}\")\n",
        "        table_df.to_csv(element_csv_filename)\n",
        "\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    _log.info(f\"Document converted and tables exported in {end_time:.2f} seconds.\")\n",
        "    return res\n",
        "\n",
        "# let's parse pdf from the pages 57 to 59. The pages that contain financial tables.\n",
        "# The 2024 financial report contains the data for both the year 2024 and 2023.\n",
        "raw_documents = parse_pdf(pdf_paths[0], 57, 59)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dR5knpSGdCj"
      },
      "source": [
        "### Clean text and Segment reports into logical sections\n",
        "\n",
        "The above parsed document has financial data for 2024, 2023, 2022 and 2021. Let's clean up and extract for 2024 and 2023.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTgXnWxfGdCj"
      },
      "source": [
        "#### Process INCOME statement\n",
        "1. KYNDRYL HOLDINGS, INC. CONSOLIDATED INCOME STATEMENT\n",
        "2. KYNDRYL HOLDINGS, INC. CONSOLIDATED STATEMENT OF COMPREHENSIVE INCOME (LOSS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-KdRe-DGdCj",
        "outputId": "0040c796-40eb-46fa-f7c0-c148ac561b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Questions and Answers\n",
            "[('Revenues of 2024?', '$ 16,052 million.'), ('Cost of services of 2024?', '$ 13,189 million.')]\n",
            "[('Cost of services of 2023?', '$ 14,498 million.'), ('Selling, general and administrative expenses of 2023?', '2,914 million.')]\n"
          ]
        }
      ],
      "source": [
        "from itertools import chain\n",
        "\n",
        "qa_documents = {}\n",
        "\n",
        "questions_2023 = []\n",
        "questions_2024 = []\n",
        "\n",
        "# iterate over income statement tables and create simple Q&A pairs\n",
        "for row in chain(raw_documents[0].itertuples(), raw_documents[1].itertuples()):\n",
        "    if not row[3] and not row[4]:\n",
        "        continue\n",
        "    question_suffix = \"?\"\n",
        "    question_prefix = f'{row[1].strip(\".* :\").strip()} of'\n",
        "    answer_suffix = \".\" if \"per share\" in question_prefix.lower() else \" million.\"\n",
        "\n",
        "    question = question_prefix + \" 2024\" + question_suffix\n",
        "    answer = row[3]\n",
        "    answer = \"Not applicable\" if answer == \"-\" else (answer + answer_suffix)\n",
        "    questions_2024.append((question, answer))\n",
        "\n",
        "    question = question_prefix + \" 2023\" + question_suffix\n",
        "    answer = row[4]\n",
        "    answer = \"Not applicable\" if answer == \"-\" else (answer + answer_suffix)\n",
        "    questions_2023.append((question, answer))\n",
        "\n",
        "print(\"Sample Questions and Answers\")\n",
        "print(questions_2024[:2])\n",
        "print(questions_2023[1:3])\n",
        "\n",
        "qa_documents['Income Statement 2024'] = questions_2024\n",
        "qa_documents['Income Statement 2023'] = questions_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueEui4aVGdCj"
      },
      "source": [
        "#### Process KYNDRYL HOLDINGS, INC. CONSOLIDATED BALANCE SHEET\n",
        "(In millions, except per share amounts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5J6Q9jHGdCj",
        "outputId": "1cde443d-2029-4c39-8c2b-2a5ebdc7c71c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Questions and Answers\n",
            "[('Other noncurrent liabilities of 2024?', '332 million.'), ('Total liabilities of 2024?', '$ 9,468 million.')]\n",
            "[('Total liabilities of 2023?', '$ 10,002 million.')]\n",
            "Total 2024 Q&A pairs: 26\n",
            "Total 2023 Q&A pairs: 26\n"
          ]
        }
      ],
      "source": [
        "questions_2023 = []\n",
        "questions_2024 = []\n",
        "common_prefix = \"\"\n",
        "skip = False\n",
        "\n",
        "# iterate over the balance sheet table and create simple Q&A pairs\n",
        "for row in raw_documents[2].itertuples():\n",
        "    question_suffix = \"?\"\n",
        "    question_prefix = f'{row[1].strip(\".* :\").strip()}'\n",
        "    if question_prefix.endswith(\"Assets\") and not row[3]:\n",
        "        common_prefix = \" assets\"\n",
        "    elif question_prefix.endswith(\"Liabilities\") and not row[3]:\n",
        "        common_prefix = \" liabilities\"\n",
        "    elif question_prefix.endswith(\"Equity\") and not row[3]:\n",
        "        break\n",
        "    if not row[3] and not row[4]:\n",
        "        continue\n",
        "\n",
        "    if not question_prefix:\n",
        "        skip = True\n",
        "        continue\n",
        "    elif skip:\n",
        "        skip = False\n",
        "        continue\n",
        "\n",
        "    answer_suffix = \".\" if \"per share\" in question_prefix.lower() else \" million.\"\n",
        "\n",
        "    question = (\n",
        "        (\n",
        "            question_prefix\n",
        "            if question_prefix.endswith(common_prefix)\n",
        "            else f\"{question_prefix}{common_prefix}\"\n",
        "        )\n",
        "        + \" of 2024\"\n",
        "        + question_suffix\n",
        "    )\n",
        "    answer = row[3] + answer_suffix\n",
        "    questions_2024.append((question, answer))\n",
        "    question = (\n",
        "        (\n",
        "            question_prefix\n",
        "            if question_prefix.endswith(common_prefix)\n",
        "            else f\"{question_prefix}{common_prefix}\"\n",
        "        )\n",
        "        + \" of 2023\"\n",
        "        + question_suffix\n",
        "    )\n",
        "    answer = row[4] + answer_suffix\n",
        "    questions_2023.append((question, answer))\n",
        "\n",
        "print(\"Sample Questions and Answers\")\n",
        "print(questions_2024[-2:])\n",
        "print(questions_2023[-1:])\n",
        "\n",
        "print(f\"Total 2024 Q&A pairs: {len(questions_2024)}\")\n",
        "print(f\"Total 2023 Q&A pairs: {len(questions_2023)}\")\n",
        "\n",
        "qa_documents['Balance Sheet 2024'] = questions_2024\n",
        "qa_documents['Balance Sheet 2023'] = questions_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa414si1GdCk"
      },
      "source": [
        "#### Q/A Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xd8kq2uGdCk",
        "outputId": "87ce0144-8888-4761-eabe-8a83f8c073ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Document: Income Statement 2024\n",
            "Q: Revenues of 2024?\n",
            "A: $ 16,052 million.\n",
            "\n",
            "Q: Cost of services of 2024?\n",
            "A: $ 13,189 million.\n",
            "\n",
            "Q: Selling, general and administrative expenses of 2024?\n",
            "A: 2,773 million.\n",
            "\n",
            "Q: Workforce rebalancing charges of 2024?\n",
            "A: 138 million.\n",
            "\n",
            "Q: Transaction-related costs (benefits) of 2024?\n",
            "A: (46) million.\n",
            "\n",
            "Q: Impairment expense of 2024?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Interest expense of 2024?\n",
            "A: 122 million.\n",
            "\n",
            "Q: Other expense of 2024?\n",
            "A: 45 million.\n",
            "\n",
            "Q: Total costs and expenses of 2024?\n",
            "A: $ 16,221 million.\n",
            "\n",
            "Q: Income (loss) before income taxes of 2024?\n",
            "A: $ (168) million.\n",
            "\n",
            "Q: Provision for income taxes of 2024?\n",
            "A: $ 172 million.\n",
            "\n",
            "Q: Net income (loss) of 2024?\n",
            "A: $ (340) million.\n",
            "\n",
            "Q: Basic earnings (loss) per share of 2024?\n",
            "A: $ (1.48).\n",
            "\n",
            "Q: Diluted earnings (loss) per share of 2024?\n",
            "A: (1.48).\n",
            "\n",
            "Q: Weighted-average basic shares outstanding of 2024?\n",
            "A: 229.2 million.\n",
            "\n",
            "Q: Weighted-average diluted shares outstanding of 2024?\n",
            "A: 229.2 million.\n",
            "\n",
            "Q: Net income (loss) of 2024?\n",
            "A: $ (1,374) million.\n",
            "\n",
            "Q: Foreign currency translation adjustments of 2024?\n",
            "A: (186) million.\n",
            "\n",
            "Q: Unrealized losses on net investment hedges of 2024?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Total foreign currency translation adjustments of 2024?\n",
            "A: (186) million.\n",
            "\n",
            "Q: Unrealized gains (losses) arising during the period of 2024?\n",
            "A: (4) million.\n",
            "\n",
            "Q: Reclassification of (gains) losses to net income of 2024?\n",
            "A: 2 million.\n",
            "\n",
            "Q: Total unrealized gains (losses) on cash flow hedges of 2024?\n",
            "A: (3) million.\n",
            "\n",
            "Q: Prior service costs (credits) of 2024?\n",
            "A: 4 million.\n",
            "\n",
            "Q: Net gains (losses) arising during the period of 2024?\n",
            "A: 175 million.\n",
            "\n",
            "Q: Curtailments and settlements of 2024?\n",
            "A: 10 million.\n",
            "\n",
            "Q: Amortization of prior service (credits) costs of 2024?\n",
            "A: 1 million.\n",
            "\n",
            "Q: Amortization of net (gains) losses of 2024?\n",
            "A: 40 million.\n",
            "\n",
            "Q: Total retirement-related benefit plans of 2024?\n",
            "A: 229 million.\n",
            "\n",
            "Q: Other comprehensive income (loss), before tax of 2024?\n",
            "A: 40 million.\n",
            "\n",
            "Q: Income tax (expense) benefit related to items of other comprehensive income (loss) of 2024?\n",
            "A: (14) million.\n",
            "\n",
            "Q: Other comprehensive income (loss), net of tax of 2024?\n",
            "A: 27 million.\n",
            "\n",
            "Q: Total comprehensive income (loss) of 2024?\n",
            "A: $ (1,347) million.\n",
            "\n",
            "\n",
            "Document: Income Statement 2023\n",
            "Q: Revenues of 2023?\n",
            "A: $ 17,026 million.\n",
            "\n",
            "Q: Cost of services of 2023?\n",
            "A: $ 14,498 million.\n",
            "\n",
            "Q: Selling, general and administrative expenses of 2023?\n",
            "A: 2,914 million.\n",
            "\n",
            "Q: Workforce rebalancing charges of 2023?\n",
            "A: 71 million.\n",
            "\n",
            "Q: Transaction-related costs (benefits) of 2023?\n",
            "A: 264 million.\n",
            "\n",
            "Q: Impairment expense of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Interest expense of 2023?\n",
            "A: 94 million.\n",
            "\n",
            "Q: Other expense of 2023?\n",
            "A: 35 million.\n",
            "\n",
            "Q: Total costs and expenses of 2023?\n",
            "A: $ 17,876 million.\n",
            "\n",
            "Q: Income (loss) before income taxes of 2023?\n",
            "A: $ (851) million.\n",
            "\n",
            "Q: Provision for income taxes of 2023?\n",
            "A: $ 524 million.\n",
            "\n",
            "Q: Net income (loss) of 2023?\n",
            "A: $ (1,374) million.\n",
            "\n",
            "Q: Basic earnings (loss) per share of 2023?\n",
            "A: $ (6.06).\n",
            "\n",
            "Q: Diluted earnings (loss) per share of 2023?\n",
            "A: (6.06).\n",
            "\n",
            "Q: Weighted-average basic shares outstanding of 2023?\n",
            "A: 226.7 million.\n",
            "\n",
            "Q: Weighted-average diluted shares outstanding of 2023?\n",
            "A: 226.7 million.\n",
            "\n",
            "Q: Net income (loss) of 2023?\n",
            "A: $ (229) million.\n",
            "\n",
            "Q: Foreign currency translation adjustments of 2023?\n",
            "A: (51) million.\n",
            "\n",
            "Q: Unrealized losses on net investment hedges of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Total foreign currency translation adjustments of 2023?\n",
            "A: (51) million.\n",
            "\n",
            "Q: Unrealized gains (losses) arising during the period of 2023?\n",
            "A: 1 million.\n",
            "\n",
            "Q: Reclassification of (gains) losses to net income of 2023?\n",
            "A: (1) million.\n",
            "\n",
            "Q: Total unrealized gains (losses) on cash flow hedges of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Prior service costs (credits) of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Net gains (losses) arising during the period of 2023?\n",
            "A: 136 million.\n",
            "\n",
            "Q: Curtailments and settlements of 2023?\n",
            "A: 4 million.\n",
            "\n",
            "Q: Amortization of prior service (credits) costs of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Amortization of net (gains) losses of 2023?\n",
            "A: 16 million.\n",
            "\n",
            "Q: Total retirement-related benefit plans of 2023?\n",
            "A: 156 million.\n",
            "\n",
            "Q: Other comprehensive income (loss), before tax of 2023?\n",
            "A: 105 million.\n",
            "\n",
            "Q: Income tax (expense) benefit related to items of other comprehensive income (loss) of 2023?\n",
            "A: (50) million.\n",
            "\n",
            "Q: Other comprehensive income (loss), net of tax of 2023?\n",
            "A: 54 million.\n",
            "\n",
            "Q: Total comprehensive income (loss) of 2023?\n",
            "A: $ (175) million.\n",
            "\n",
            "\n",
            "Document: Balance Sheet 2024\n",
            "Q: Cash and cash equivalents assets of 2024?\n",
            "A: $ 1,553 million.\n",
            "\n",
            "Q: Restricted cash assets of 2024?\n",
            "A: 1 million.\n",
            "\n",
            "Q: Accounts receivable (net of allowances for credit losses of $22 at March 31, 2024 and $32 at March 31, 2023) assets of 2024?\n",
            "A: 1,599 million.\n",
            "\n",
            "Q: Deferred costs (current portion) assets of 2024?\n",
            "A: 1,081 million.\n",
            "\n",
            "Q: Prepaid expenses and other current assets of 2024?\n",
            "A: 514 million.\n",
            "\n",
            "Q: Total current assets of 2024?\n",
            "A: $ 4,747 million.\n",
            "\n",
            "Q: Deferred costs (noncurrent portion) assets of 2024?\n",
            "A: 920 million.\n",
            "\n",
            "Q: Deferred taxes assets of 2024?\n",
            "A: 220 million.\n",
            "\n",
            "Q: Goodwill assets of 2024?\n",
            "A: 805 million.\n",
            "\n",
            "Q: Intangible assets, net assets of 2024?\n",
            "A: 188 million.\n",
            "\n",
            "Q: Pension assets of 2024?\n",
            "A: 105 million.\n",
            "\n",
            "Q: Other noncurrent assets of 2024?\n",
            "A: 67 million.\n",
            "\n",
            "Q: Total assets of 2024?\n",
            "A: $ 10,590 million.\n",
            "\n",
            "Q: Accounts payable liabilities of 2024?\n",
            "A: $ 1,408 million.\n",
            "\n",
            "Q: Value-added tax and income tax liabilities of 2024?\n",
            "A: 327 million.\n",
            "\n",
            "Q: Current portion of long-term debt liabilities of 2024?\n",
            "A: 126 million.\n",
            "\n",
            "Q: Accrued compensation and benefits liabilities of 2024?\n",
            "A: 609 million.\n",
            "\n",
            "Q: Deferred income (current portion) liabilities of 2024?\n",
            "A: 825 million.\n",
            "\n",
            "Q: Operating lease liabilities (current portion) liabilities of 2024?\n",
            "A: 285 million.\n",
            "\n",
            "Q: Accrued contract costs liabilities of 2024?\n",
            "A: 487 million.\n",
            "\n",
            "Q: Other accrued expenses and liabilities of 2024?\n",
            "A: 521 million.\n",
            "\n",
            "Q: Total current liabilities of 2024?\n",
            "A: $ 4,589 million.\n",
            "\n",
            "Q: Long-term debt liabilities of 2024?\n",
            "A: $ 3,112 million.\n",
            "\n",
            "Q: Retirement and nonpension postretirement benefit obligations liabilities of 2024?\n",
            "A: 500 million.\n",
            "\n",
            "Q: Other noncurrent liabilities of 2024?\n",
            "A: 332 million.\n",
            "\n",
            "Q: Total liabilities of 2024?\n",
            "A: $ 9,468 million.\n",
            "\n",
            "\n",
            "Document: Balance Sheet 2023\n",
            "Q: Cash and cash equivalents assets of 2023?\n",
            "A: $ 1,847 million.\n",
            "\n",
            "Q: Restricted cash assets of 2023?\n",
            "A: 12 million.\n",
            "\n",
            "Q: Accounts receivable (net of allowances for credit losses of $22 at March 31, 2024 and $32 at March 31, 2023) assets of 2023?\n",
            "A: 1,523 million.\n",
            "\n",
            "Q: Deferred costs (current portion) assets of 2023?\n",
            "A: 1,070 million.\n",
            "\n",
            "Q: Prepaid expenses and other current assets of 2023?\n",
            "A: 510 million.\n",
            "\n",
            "Q: Total current assets of 2023?\n",
            "A: $ 4,963 million.\n",
            "\n",
            "Q: Deferred costs (noncurrent portion) assets of 2023?\n",
            "A: 1,166 million.\n",
            "\n",
            "Q: Deferred taxes assets of 2023?\n",
            "A: 248 million.\n",
            "\n",
            "Q: Goodwill assets of 2023?\n",
            "A: 812 million.\n",
            "\n",
            "Q: Intangible assets, net assets of 2023?\n",
            "A: 171 million.\n",
            "\n",
            "Q: Pension assets of 2023?\n",
            "A: 94 million.\n",
            "\n",
            "Q: Other noncurrent assets of 2023?\n",
            "A: 267 million.\n",
            "\n",
            "Q: Total assets of 2023?\n",
            "A: $ 11,464 million.\n",
            "\n",
            "Q: Accounts payable liabilities of 2023?\n",
            "A: $ 1,774 million.\n",
            "\n",
            "Q: Value-added tax and income tax liabilities of 2023?\n",
            "A: 347 million.\n",
            "\n",
            "Q: Current portion of long-term debt liabilities of 2023?\n",
            "A: 110 million.\n",
            "\n",
            "Q: Accrued compensation and benefits liabilities of 2023?\n",
            "A: 533 million.\n",
            "\n",
            "Q: Deferred income (current portion) liabilities of 2023?\n",
            "A: 820 million.\n",
            "\n",
            "Q: Operating lease liabilities (current portion) liabilities of 2023?\n",
            "A: 316 million.\n",
            "\n",
            "Q: Accrued contract costs liabilities of 2023?\n",
            "A: 346 million.\n",
            "\n",
            "Q: Other accrued expenses and liabilities of 2023?\n",
            "A: 624 million.\n",
            "\n",
            "Q: Total current liabilities of 2023?\n",
            "A: $ 4,868 million.\n",
            "\n",
            "Q: Long-term debt liabilities of 2023?\n",
            "A: $ 3,111 million.\n",
            "\n",
            "Q: Retirement and nonpension postretirement benefit obligations liabilities of 2023?\n",
            "A: 504 million.\n",
            "\n",
            "Q: Other noncurrent liabilities of 2023?\n",
            "A: 450 million.\n",
            "\n",
            "Q: Total liabilities of 2023?\n",
            "A: $ 10,002 million.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for doc, questions in qa_documents.items():\n",
        "    print(f\"\\nDocument: {doc}\")\n",
        "    for q, a in questions:\n",
        "        print(f\"Q: {q}\\nA: {a}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pcgQyE8GdCk"
      },
      "source": [
        "### Part 2: Retrieval-Augmented Generation (RAG) System Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K433WdQGdCk"
      },
      "source": [
        "**2.1 Data Processing: Chunking**\n",
        "\n",
        "To prepare the text for retrieval, we'll split it into smaller, manageable chunks. This allows the model to find more specific and relevant passages. We will create two sets of chunks with different sizes (100 and 400 tokens) to analyze the impact of chunk size on retrieval performance. Each chunk will be assigned a unique ID and metadata indicating its source document and chunk size.\n",
        "\n",
        "The metadata will have info whether the chunk is courced from balance sheet or income statement segments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoO_WA49GdCk",
        "outputId": "a8093287-a34d-4d40-c97c-cab587860987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of chunks created: 236\n",
            "Sample chunk: {'id': 'Income Statement 2024_0_size_100_chunk_0', 'text': 'q : revenues of 2024? a : $ 16, 052 million.', 'metadata': {'segment': 'Income Statement 2024', 'qa_index': 0, 'chunk_size': 100}}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(qa_list, chunk_size, source_key):\n",
        "    chunks = []\n",
        "    for idx, (q, a) in enumerate(qa_list):\n",
        "        text_block = f\"Q: {q}\\nA: {a}\"\n",
        "        tokens = tokenizer.encode(text_block)\n",
        "        for i in range(0, len(tokens), chunk_size):\n",
        "            chunk_tokens = tokens[i:i + chunk_size]\n",
        "            chunk_str = tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
        "            chunks.append({\n",
        "                \"id\": f\"{source_key}_{idx}_size_{chunk_size}_chunk_{len(chunks)}\",\n",
        "                \"text\": chunk_str,\n",
        "                \"metadata\": {\n",
        "                    \"segment\": source_key,\n",
        "                    \"qa_index\": idx,\n",
        "                    \"chunk_size\": chunk_size\n",
        "                }\n",
        "            })\n",
        "    return chunks\n",
        "\n",
        "chunk_sizes = [100, 400]\n",
        "all_chunks = []\n",
        "\n",
        "for size in chunk_sizes:\n",
        "    for key in qa_documents:\n",
        "        all_chunks.extend(chunk_text(qa_documents[key], size, key))\n",
        "\n",
        "print(f\"Total number of chunks created: {len(all_chunks)}\")\n",
        "print(\"Sample chunk:\", all_chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-fFvNT8GdCk"
      },
      "source": [
        "**2.2 Embedding & Indexing**\n",
        "\n",
        "Next, we will convert the text chunks into numerical vectors (embeddings) using the `all-MiniLM-L6-v2` model. These embeddings capture the semantic meaning of the text.\n",
        "\n",
        "We will build two types of indexes:\n",
        "1.  **Dense Vector Store (FAISS):** For fast semantic similarity search.\n",
        "2.  **Sparse Index (BM25):** For efficient keyword-based retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "6a3b9ec8145f4fa09f9b40e0162a7dee",
            "faff4591f0ab45108a48603e7d2be814",
            "6deb5da94ab54c8386a4d86bb6a5dfea",
            "870d4def46f64cda83477152afb9bb32",
            "0c69a1b5abc5488a8e68ff504d7c0743",
            "a99d88f6aa244195a3ba75bdbb7c4b3b",
            "d16b71bebf344c3d85349a681fa26080",
            "68fc5d7d6958449b82414901d8e2a930",
            "79a93d0964d14a18a494bc951cc2bbde",
            "327145d1365b4a74add34098ce9ae446",
            "d8617592a52c4854b37da5fdb50daa97"
          ]
        },
        "id": "NbaKG0kaGdCk",
        "outputId": "ffd1c40c-81bc-4642-b503-64ea0642a050"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a3b9ec8145f4fa09f9b40e0162a7dee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index built with 236 vectors.\n",
            "BM25 index built.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# 1. Embed Chunks\n",
        "embedding_model = SentenceTransformer(model_name)\n",
        "chunk_texts = [chunk['text'] for chunk in all_chunks]\n",
        "embeddings = embedding_model.encode(chunk_texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# 2. Build Dense Vector Store (FAISS)\n",
        "embedding_dim = embeddings.shape[1]\n",
        "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
        "faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
        "print(f\"FAISS index built with {faiss_index.ntotal} vectors.\")\n",
        "\n",
        "# 3. Build Sparse Index (BM25)\n",
        "tokenized_corpus = [doc.lower().split(\" \") for doc in chunk_texts]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "print(\"BM25 index built.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvdVUFWRGdCk"
      },
      "source": [
        "**2.3 Hybrid Retrieval Pipeline**\n",
        "\n",
        "Our retrieval pipeline will combine the strengths of both dense and sparse methods. For a given query, we will:\n",
        "1. Preprocess the query.\n",
        "2. Retrieve the top N chunks from FAISS based on vector similarity.\n",
        "3. Retrieve the top N chunks from BM25 based on keyword matching.\n",
        "4. Combine the results using a simple union to create a comprehensive list of candidate chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "leXIMB6fGdCk"
      },
      "outputs": [],
      "source": [
        "def preprocess_query(query):\n",
        "    # Normalize\n",
        "    query = query.lower()\n",
        "\n",
        "    # All the queries are about Kyndryl. So, let's remove that, it might bias the retriever\n",
        "    # Remove redundant keywords\n",
        "    stopwords = [\"kyndryl\", \"IBM\", \"company\", \"inc\", \"inc.\", \"corporation\", \"corp\", \"corp.\", \"ltd\", \"ltd.\", \"plc\", \"the\"]\n",
        "    for w in stopwords:\n",
        "        query = query.replace(w.lower(), \"\")\n",
        "    return query.strip()\n",
        "\n",
        "def hybrid_retrieve(query, top_n=5):\n",
        "    # 1. Preprocess query\n",
        "    clean_query = preprocess_query(query)\n",
        "\n",
        "    # 2. Dense Retrieval (FAISS)\n",
        "    query_embedding = embedding_model.encode([clean_query])\n",
        "    _, dense_indices = faiss_index.search(np.array(query_embedding, dtype=np.float32), top_n)\n",
        "    dense_results = [all_chunks[i] for i in dense_indices[0]]\n",
        "\n",
        "    # 3. Sparse Retrieval (BM25)\n",
        "    tokenized_query = clean_query.split(\" \")\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    sparse_indices = np.argsort(bm25_scores)[::-1][:top_n]\n",
        "    sparse_results = [all_chunks[i] for i in sparse_indices]\n",
        "\n",
        "    # 4. Combine results\n",
        "    combined_results_dict = {chunk['id']: chunk for chunk in dense_results + sparse_results}\n",
        "\n",
        "    print(f\"Retrieved {len(dense_results)} chunks from dense search.\")\n",
        "    print(f\"Retrieved {len(sparse_results)} chunks from sparse search.\")\n",
        "    print(f\"Combined to {len(combined_results_dict)} unique chunks.\")\n",
        "\n",
        "    return list(combined_results_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "echsdYb4GdCk",
        "outputId": "8f454168-1d35-4809-d6a4-fb7f5f766a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "\n",
            "--- Top Retrieved Chunk for 'What was the company's revenue in 2024?' ---\n",
            "q : revenues of 2024? a : $ 16, 052 million.\n"
          ]
        }
      ],
      "source": [
        "# Example Usage\n",
        "test_query = \"What was the company's revenue in 2024?\"\n",
        "retrieved_chunks = hybrid_retrieve(test_query)\n",
        "\n",
        "print(f\"\\n--- Top Retrieved Chunk for '{test_query}' ---\")\n",
        "print(retrieved_chunks[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85BY6bLzGdCk"
      },
      "source": [
        "**2.4 Advanced RAG Technique: Cross-Encoder Re-ranking**\n",
        "\n",
        "The initial retrieval might return chunks that are only partially relevant. To refine our results, we'll use a Cross-Encoder model. Unlike the embedding model which computes vectors independently, a Cross-Encoder takes both the query and a candidate chunk as input to produce a more accurate relevance score. We will use this to re-rank the top chunks retrieved from our hybrid pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mbiRXVHHGdCk"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "\n",
        "# Load a cross-encoder model\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "def rerank_with_cross_encoder(query, chunks):\n",
        "    # Create pairs of [query, chunk_text] for scoring\n",
        "    query_chunk_pairs = [[query, chunk['text']] for chunk in chunks]\n",
        "\n",
        "    # Get scores from the cross-encoder\n",
        "    scores = cross_encoder.predict(query_chunk_pairs, show_progress_bar=False)\n",
        "\n",
        "    # Add scores to chunks and sort\n",
        "    for i in range(len(chunks)):\n",
        "        chunks[i]['relevance_score'] = scores[i]\n",
        "\n",
        "    reranked_chunks = sorted(chunks, key=lambda x: x['relevance_score'], reverse=True)\n",
        "    return reranked_chunks\n",
        "\n",
        "\n",
        "def advanced_retrieve(query):\n",
        "    retrieved_chunks = hybrid_retrieve(query)\n",
        "    reranked_results = rerank_with_cross_encoder(query, retrieved_chunks)\n",
        "    return reranked_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTwUsa3mGdCk",
        "outputId": "fa3bda71-2b20-4fc4-90e2-6a2228d8e5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "\n",
            "--- Top Re-ranked Chunk for 'What was the company's revenue in 2024?' ---\n",
            "Relevance Score: 8.9147\n",
            "q : revenues of 2024? a : $ 16, 052 million.\n"
          ]
        }
      ],
      "source": [
        "# Example Usage with the same test query\n",
        "test_query = \"What was the company's revenue in 2024?\"\n",
        "reranked_results = advanced_retrieve(test_query)\n",
        "print(f\"\\n--- Top Re-ranked Chunk for '{test_query}' ---\")\n",
        "print(f\"Relevance Score: {reranked_results[0]['relevance_score']:.4f}\")\n",
        "print(reranked_results[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGVWiCa7GdCk"
      },
      "source": [
        "**2.5 Response Generation**\n",
        "\n",
        "After retrieving and re-ranking the most relevant document chunks, the final step is to generate a coherent, human-readable answer. We will use a generative language model to synthesize the information from the retrieved passages into a direct response to the user's query.\n",
        "\n",
        "For this demonstration, we'll use `Flan T5`, a smaller and more efficient version, which is suitable for tasks where resource constraints are a consideration. The retrieved text and the original query are combined into a carefully crafted prompt to guide the model in generating a factual answer grounded in the provided context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z0xOG6sGdCk",
        "outputId": "f7877f0f-c4b4-410c-8300-8b92d0bc4f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# --- Configuration ---\n",
        "model_name = \"google/flan-t5-base\"\n",
        "# Explicitly set the device to ensure all tensors are on the same hardware\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Model and Tokenizer Loading ---\n",
        "try:\n",
        "    gen_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    # Ensure the model is moved to the correct device upon loading\n",
        "    gen_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Please ensure you have a stable internet connection.\")\n",
        "    exit()\n",
        "\n",
        "# Note: The 'pipeline' object is no longer used in the generation function.\n",
        "\n",
        "def generate_answer(query, reranked_chunks, max_new_tokens=100):\n",
        "    \"\"\"\n",
        "    Generates an answer using the model directly and calculates its confidence score.\n",
        "    \"\"\"\n",
        "    # 1. Prepare the context\n",
        "    context = \"\\n\\n\".join([chunk.get(\"text\", \"\") for chunk in reranked_chunks[:3]])\n",
        "\n",
        "    # 2. Create the prompt\n",
        "    prompt = f\"\"\"\n",
        "Based on the following context, please answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    # 3. Manually tokenize the input and move it to the model's device\n",
        "    inputs = gen_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # 4. Use model.generate() directly. This returns the raw output object.\n",
        "    generated_output = gen_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_return_sequences=1,\n",
        "        num_beams=4,  # Using beam search\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "    )\n",
        "\n",
        "    # --- 5. Calculate Confidence Score ---\n",
        "    # We now access the attributes directly from the raw output object.\n",
        "    # These attributes are guaranteed to be the correct tensor types.\n",
        "    transition_scores = gen_model.compute_transition_scores(\n",
        "        sequences=generated_output.sequences,\n",
        "        scores=generated_output.scores,\n",
        "        beam_indices=generated_output.beam_indices,\n",
        "        normalize_logits=True\n",
        "    )\n",
        "\n",
        "    # To get the final probability, exponentiate the sum of the log-probabilities\n",
        "    confidence = torch.exp(transition_scores.sum()).item()\n",
        "\n",
        "    # 6. Manually decode the output token IDs to get the answer text\n",
        "    # We take the first (and only) generated sequence.\n",
        "    output_sequence = generated_output.sequences[0]\n",
        "    answer = gen_tokenizer.decode(output_sequence, skip_special_tokens=True)\n",
        "\n",
        "    # 7. Return both the answer and its confidence score\n",
        "    return answer.strip(), confidence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzmIyC3UGdCk",
        "outputId": "89752daa-0cd8-4f62-8aa1-ba3968c6dc3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is fiscal year 2024 revenue?\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "\n",
            "Generated Answer:\n",
            "$ 16, 052 million\n"
          ]
        }
      ],
      "source": [
        "def query_finance_system_rag(query, debug = False):\n",
        "    reranked_results = advanced_retrieve(query)\n",
        "\n",
        "    if debug:\n",
        "        for r in reranked_results:\n",
        "            print('-----')\n",
        "            print(r['text'])\n",
        "\n",
        "    # Example Usage\n",
        "    start_time = time.time()\n",
        "    final_answer, confidence = generate_answer(query, reranked_results)\n",
        "    end_time = time.time()\n",
        "    latency = end_time - start_time\n",
        "\n",
        "    return final_answer, latency, confidence\n",
        "\n",
        "test_query = \"What is fiscal year 2024 revenue?\"\n",
        "print(f\"Question: {test_query}\")\n",
        "final_answer, _, _ = query_finance_system_rag(test_query)\n",
        "print(f\"\\nGenerated Answer:\\n{final_answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybP7XhyAGdCk"
      },
      "source": [
        "**2.6 Guardrail Implementation**\n",
        "\n",
        "To ensure the reliability and safety of our RAG system, we need to implement guardrails. These are checks and balances that prevent the system from processing inappropriate queries or generating harmful, irrelevant, or factually incorrect answers. We will implement two basic guardrails:\n",
        "\n",
        "1.  **Input Guardrail:** A simple filter to block off-topic or nonsensical questions.\n",
        "2.  **Output Guardrail:** A check to ensure the generated answer is grounded in the retrieved context and not a hallucination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKLRUEoUGdCl",
        "outputId": "f5cec81a-e795-4686-e5cf-2a68b3ab90aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Input Guardrail Tests ---\n",
            "Query: 'What were the total assets of Kyndryl as of March 31, 2024?' -> Valid: True, Reason: Query is valid.\n",
            "Query: 'revenue?' -> Valid: False, Reason: Query is too short. Please ask a more specific question.\n",
            "Query: 'Can you give me a recipe for a cake?' -> Valid: False, Reason: Query is off-topic. This system is for financial document analysis.\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- Output Guardrail Tests ---\n",
            "Answer: '$ 16, 052 million...' -> Grounded: True, Reason: Answer appears grounded in context (Overlap: 75.00%).\n",
            "Answer: 'Kyndryl announced a partnership with SpaceX to build datacenters on Mars.' -> Grounded: False, Reason: Potential hallucination detected. Answer may not be grounded in context (Overlap: 9.09%).\n"
          ]
        }
      ],
      "source": [
        "# --- Input Guardrail ---\n",
        "\n",
        "def validate_query(query):\n",
        "    \"\"\"\n",
        "    Validates the input query to filter out irrelevant or harmful inputs.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "\n",
        "    # Check for minimum length\n",
        "    if len(query.split()) < 3:\n",
        "        return False, \"Query is too short. Please ask a more specific question.\"\n",
        "\n",
        "    # Basic check for off-topic keywords\n",
        "    off_topic_keywords = ['recipe', 'poem', 'joke', 'movie', 'celebrity', 'sports', 'weather', 'travel', 'music', 'game', 'politics', 'history', 'science fiction']\n",
        "    if any(keyword in query for keyword in off_topic_keywords):\n",
        "        return False, \"Query is off-topic. This system is for financial document analysis.\"\n",
        "\n",
        "    return True, \"Query is valid.\"\n",
        "\n",
        "# --- Output Guardrail ---\n",
        "\n",
        "def validate_output(answer, retrieved_chunks):\n",
        "    \"\"\"\n",
        "    Validates the generated output to flag potential hallucinations.\n",
        "    This is a simple check based on keyword overlap.\n",
        "    \"\"\"\n",
        "    context = \" \".join([chunk['text'].lower() for chunk in retrieved_chunks])\n",
        "    answer_tokens = set(answer.lower().split())\n",
        "    context_tokens = set(context.split())\n",
        "\n",
        "    if not answer_tokens:\n",
        "        return False, \"Generated answer is empty.\"\n",
        "\n",
        "    # Calculate the percentage of answer tokens that are present in the context\n",
        "    overlap = answer_tokens.intersection(context_tokens)\n",
        "    overlap_ratio = len(overlap) / len(answer_tokens)\n",
        "\n",
        "    # If overlap is less than a certain threshold (e.g., 30%), flag it as potentially ungrounded.\n",
        "    if overlap_ratio < 0.3:\n",
        "        return False, f\"Potential hallucination detected. Answer may not be grounded in context (Overlap: {overlap_ratio:.2%}).\"\n",
        "\n",
        "    return True, f\"Answer appears grounded in context (Overlap: {overlap_ratio:.2%}).\"\n",
        "\n",
        "\n",
        "# --- Example Usage of Guardrails ---\n",
        "\n",
        "# 1. Input Guardrail Examples\n",
        "print(\"--- Input Guardrail Tests ---\")\n",
        "valid_query = \"What were the total assets of Kyndryl as of March 31, 2024?\"\n",
        "invalid_query_short = \"revenue?\"\n",
        "invalid_query_topic = \"Can you give me a recipe for a cake?\"\n",
        "\n",
        "is_valid, reason = validate_query(valid_query)\n",
        "print(f\"Query: '{valid_query}' -> Valid: {is_valid}, Reason: {reason}\")\n",
        "\n",
        "is_valid, reason = validate_query(invalid_query_short)\n",
        "print(f\"Query: '{invalid_query_short}' -> Valid: {is_valid}, Reason: {reason}\")\n",
        "\n",
        "is_valid, reason = validate_query(invalid_query_topic)\n",
        "print(f\"Query: '{invalid_query_topic}' -> Valid: {is_valid}, Reason: {reason}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# 2. Output Guardrail Example\n",
        "print(\"--- Output Guardrail Tests ---\")\n",
        "# Use the previously generated answer\n",
        "is_grounded, reason = validate_output(final_answer, reranked_results)\n",
        "print(f\"Answer: '{final_answer[:100]}...' -> Grounded: {is_grounded}, Reason: {reason}\")\n",
        "\n",
        "# Example of a potentially hallucinated answer\n",
        "hallucinated_answer = \"Kyndryl announced a partnership with SpaceX to build datacenters on Mars.\"\n",
        "is_grounded, reason = validate_output(hallucinated_answer, reranked_results)\n",
        "print(f\"Answer: '{hallucinated_answer}' -> Grounded: {is_grounded}, Reason: {reason}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCoFg-QQlaaY"
      },
      "source": [
        "2.7 Interface Development\n",
        "\n",
        "UI is built at the end together with finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4z5UyPMGdCl"
      },
      "source": [
        "### 3. Fine-Tuned Model System Implementation\n",
        "\n",
        "\n",
        "#### 3.1 Q/A Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwuQTbCwGdCl",
        "outputId": "bc32810a-ddec-4e21-f7a0-626e444cde80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'question: Total liabilities of 2023? answer: $ 10,002 million.'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convert to a list of dictionaries for the dataset\n",
        "fine_tuning_data = []\n",
        "for doc_id, questions in qa_documents.items():\n",
        "    fine_tuning_data.extend(\n",
        "        [\n",
        "            {\"text\": f\"question: {question} answer: {answer}\"}\n",
        "            for question, answer in questions\n",
        "        ]\n",
        "    )\n",
        "\n",
        "df = pd.DataFrame(fine_tuning_data)\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "\n",
        "print(dataset[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-WcFHs7GdCl"
      },
      "source": [
        "#### 3.2 Model Selection\n",
        "\n",
        "we will use the google/flan-t5-base model as RAG setup. This is a versatile and powerful model that is well-suited for a variety of NLP tasks, including question answering and demands less hardware.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "o0-xrvfqGdCl"
      },
      "outputs": [],
      "source": [
        "model_name = 'google/flan-t5-base'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFf1NQ2GlhQK"
      },
      "source": [
        "### 3.3 Baseline Benchmarking (Pre-Fine-Tuning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X6TJP9CvLPX",
        "outputId": "849b0599-9734-4248-bc0f-6ef7725cf572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 5 unique chunks.\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "|    | Method   | Query                                                              | Response             | Ground Truth       |   Accuracy |   Latency (s) |   Confidence |\n",
            "|---:|:---------|:-------------------------------------------------------------------|:---------------------|:-------------------|-----------:|--------------:|-------------:|\n",
            "|  0 | RAG      | What were the total revenues in fiscal 2024?                       | $ 16, 052 million    | $ 16,052 million.  |      0.977 |         0.522 |    0.624393  |\n",
            "|  1 | RAG      | What were the total score in fiscal 2023?                          | $ ( 175 ) million    | Not applicable     |      0.14  |         0.676 |    0.0169149 |\n",
            "|  2 | RAG      | Cost of services of 2024?                                          | 13, 189 million      | $ 13,189 million.  |      0.87  |         0.369 |    0.732187  |\n",
            "|  3 | RAG      | What was the cost of services in fiscal 2023?                      | $ 14, 498 million    | $ 14,498 million.  |      0.98  |         0.293 |    0.171587  |\n",
            "|  4 | RAG      | What was the net income (loss) reported in fiscal 2024?            | $ ( 1, 374 ) million | $ (340) million.   |      0.712 |         0.255 |    0.39201   |\n",
            "|  5 | RAG      | What was the net income (loss) reported in fiscal 2023?            | $ ( 1, 374 ) million | $ (1,374) million. |      0.98  |         0.222 |    0.184213  |\n",
            "|  6 | RAG      | Cookie recipe?                                                     | (iii).               | Not Applicable     |      0.326 |         0.152 |    0.005674  |\n",
            "|  7 | RAG      | How much were the total liabilities in fiscal 2023?                | $ 10, 002 million    | $ 10,002 million.  |      0.978 |         0.216 |    0.17307   |\n",
            "|  8 | RAG      | What were the cash and cash equivalents at the end of fiscal 2024? | $ 1, 553 million     | $ 1,553 million.   |      0.971 |         0.199 |    0.851834  |\n",
            "|  9 | RAG      | What were the cash and cash equivalents at the end of fiscal 2023? | $ 1, 847 million     | $ 1,847 million.   |      0.968 |         0.178 |    0.815999  |\n",
            "RAG with response generation evaluated.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def semantic_similarity(a, b):\n",
        "    emb_a = embedding_model.encode([a])\n",
        "    emb_b = embedding_model.encode([b])\n",
        "    return float(\n",
        "        torch.cosine_similarity(torch.tensor(emb_a), torch.tensor(emb_b)).item()\n",
        "    )\n",
        "\n",
        "\n",
        "test_questions_10 = [\n",
        "    {\n",
        "        \"question\": \"What were the total revenues in fiscal 2024?\",\n",
        "        \"ground_truth\": \"$ 16,052 million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What were the total score in fiscal 2023?\",\n",
        "        \"ground_truth\": \"Not applicable\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Cost of services of 2024?\",\n",
        "        \"ground_truth\": \"$ 13,189 million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What was the cost of services in fiscal 2023?\",\n",
        "        \"ground_truth\": \"$ 14,498 million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What was the net income (loss) reported in fiscal 2024?\",\n",
        "        \"ground_truth\": \"$ (340) million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What was the net income (loss) reported in fiscal 2023?\",\n",
        "        \"ground_truth\": \"$ (1,374) million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Cookie recipe?\",\n",
        "        \"ground_truth\": \"Not Applicable\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How much were the total liabilities in fiscal 2023?\",\n",
        "        \"ground_truth\": \"$ 10,002 million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What were the cash and cash equivalents at the end of fiscal 2024?\",\n",
        "        \"ground_truth\": \"$ 1,553 million.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What were the cash and cash equivalents at the end of fiscal 2023?\",\n",
        "        \"ground_truth\": \"$ 1,847 million.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "def evaluate(test_questions, rag=True, fine_tuning=False):\n",
        "    evaluations = []\n",
        "    for test_question in test_questions:\n",
        "        query = test_question[\"question\"]\n",
        "        truth = test_question[\"ground_truth\"]\n",
        "\n",
        "        if rag:\n",
        "            answer, latency, confidence = query_finance_system_rag(query)\n",
        "            evaluations.append({\n",
        "                \"Method\": \"RAG\",\n",
        "                \"Query\": query,\n",
        "                \"Response\": answer,\n",
        "                \"Ground Truth\": truth,\n",
        "                \"Accuracy\": round(\n",
        "                    1 if answer.strip() == truth.strip()\n",
        "                    else semantic_similarity(answer, truth), 3\n",
        "                ),\n",
        "                \"Latency (s)\": round(latency, 3),\n",
        "                \"Confidence\": confidence\n",
        "            })\n",
        "\n",
        "        if fine_tuning:\n",
        "            answer, latency, confidence = query_finance_system_finetune(query)\n",
        "            evaluations.append({\n",
        "                \"Method\": \"Fine-Tune\",\n",
        "                \"Query\": query,\n",
        "                \"Response\": answer,\n",
        "                \"Ground Truth\": truth,\n",
        "                \"Accuracy\": round(\n",
        "                    1 if answer.strip() == truth.strip()\n",
        "                    else semantic_similarity(answer, truth), 3\n",
        "                ),\n",
        "                \"Latency (s)\": round(latency, 3),\n",
        "                \"Confidence\": confidence\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(evaluations)\n",
        "    print(df.to_markdown())\n",
        "    return df\n",
        "\n",
        "\n",
        "# evaluate pre-finetuned system\n",
        "evaluate(test_questions_10, True, False)\n",
        "print('RAG with response generation evaluated.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNvO87JGdCl"
      },
      "source": [
        "### 3.4 Fine-Tuning\n",
        "Now we will fine-tune the selected model on our prepared Q/A dataset. We will use the transformers library from Hugging Face for this task. We'll also log the hyperparameters used in the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "ea3cf65453be471d8acfd6e40accaba3",
            "2393442f5e6c45caa20a6df4e745d951",
            "9d26812b50324348b2681c017a99ed71",
            "10d2b200ba564f25b136c9bac0fd8dd5",
            "af9b89e81ef34515aa4056b0d4e5a391",
            "b2d1cf23642848ac8bd9784a92e034f7",
            "106e9e2a6f434411ac746d2333880c4b",
            "89f9112a1bee481484acc814bbeafb5d",
            "d839c92368ed44168ac947f8bba2d4de",
            "9f49919dd21649149f6f6660321fe803",
            "08fb5ced3680467f8f868dc368fbeccf"
          ]
        },
        "id": "J8nzYZGwGdCl",
        "outputId": "87ce3f69-dd84-45ee-8798-7b943bd0e102"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3cf65453be471d8acfd6e40accaba3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/118 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters:\n",
            "  Learning Rate: 2e-05\n",
            "  Batch Size: 8\n",
            "  Number of Epochs: 3\n",
            "  Compute Setup: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1283009621.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjawaharbtech\u001b[0m (\u001b[33mjawahar-s\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250823_223943-tkx47duv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jawahar-s/huggingface/runs/tkx47duv' target=\"_blank\">earthy-water-2</a></strong> to <a href='https://wandb.ai/jawahar-s/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jawahar-s/huggingface' target=\"_blank\">https://wandb.ai/jawahar-s/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jawahar-s/huggingface/runs/tkx47duv' target=\"_blank\">https://wandb.ai/jawahar-s/huggingface/runs/tkx47duv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [45/45 01:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=45, training_loss=25.108327907986112, metrics={'train_runtime': 239.4901, 'train_samples_per_second': 1.478, 'train_steps_per_second': 0.188, 'total_flos': 60601025691648.0, 'train_loss': 25.108327907986112, 'epoch': 3.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex for ex in examples[\"text\"]]\n",
        "    # The model expects 'labels' for the target text\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # The T5 model needs the decoder input_ids to be created from the labels\n",
        "    # The Trainer does this automatically if the 'labels' field is present.\n",
        "    # We just need to make sure our tokenized outputs have a 'labels' key.\n",
        "    # For T5, the input and output are the same text sequence for this task.\n",
        "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define the training arguments\n",
        "# NOTE: The 'evaluation_strategy' and 'device' arguments have been removed.\n",
        "# 'do_eval=True' enables evaluation, which defaults to the end of each epoch.\n",
        "# The Trainer will automatically use the GPU if it's available.\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    do_eval=True,  # Enable evaluation\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# Log the hyperparameters\n",
        "print(\"Hyperparameters:\")\n",
        "print(f\"  Learning Rate: {training_args.learning_rate}\")\n",
        "print(f\"  Batch Size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Number of Epochs: {training_args.num_train_epochs}\")\n",
        "\n",
        "# Determine compute setup and log it\n",
        "compute_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"  Compute Setup: {compute_device}\")\n",
        "\n",
        "\n",
        "# Create the data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqF4IptJWfBp",
        "outputId": "eb0dd54a-d73e-4534-ac53-075ce21e5682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Testing the Fine-Tuned Model from Section 3.3 ---\n",
            "\n",
            "Q: Total assets of 2023?\n",
            "A: 2 billion\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n--- Testing the Fine-Tuned Model from Section 3.3 ---\")\n",
        "\n",
        "# Save the final model\n",
        "trainer.save_model(\"./results_s3_3/final_model\")\n",
        "\n",
        "# Load the fine-tuned model from the checkpoint\n",
        "fine_tuned_model_3_3 = AutoModelForSeq2SeqLM.from_pretrained(\"./results_s3_3/final_model\")\n",
        "fine_tuned_model_3_3.to(compute_device)\n",
        "\n",
        "def ask_simple_finetuned_model(question):\n",
        "    # We must match the prompt format that the model was trained on\n",
        "    prompt = f\"question: {question} answer:\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(compute_device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = fine_tuned_model_3_3.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# --- Prediction and Analysis ---\n",
        "test_question = \"Total assets of 2023?\"\n",
        "predicted_answer = ask_simple_finetuned_model(test_question)\n",
        "\n",
        "print(f\"\\nQ: {test_question}\")\n",
        "print(f\"A: {predicted_answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaNjQgjFGdCl"
      },
      "source": [
        "#### 3.5 Advanced Fine-Tuning Technique (Mixture-of-Experts Fine-Tuning)\n",
        "\n",
        "We will create two specialized experts:\n",
        "\n",
        "Expert A: The \"Balance Sheet\" Expert: This expert will be a specialist on questions related to a company's assets and liabilities. These items reflect a company's financial position at a single point in time (e.g., \"as of March 31, 2023\").\n",
        "\n",
        "Expert B: The \"Income Statement\" Expert: This expert will specialize in questions about revenues, costs, and expenses. These items reflect a company's performance over a period of time (e.g., \"for the year 2024\").\n",
        "\n",
        "\n",
        "##### Step 1: Prepare and Split the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "13479c6ab9804ac08533ff00a3ec1bd2",
            "33bde37efc7243399c5869831fe33456",
            "729e58e33e7345599e171848064e233a",
            "bf962fd6614849c48c42cc4cf92def0a",
            "b380ba3e952144c9ad1d6ca8fca7af17",
            "a2674110b45949e98c31b06598367db4",
            "c8b61ef8dead4ef8b43410b7fbf34bf2",
            "44b015d67e4f4d62bab0aa12f9c1dd3c",
            "ad430b45baa2401390544eced22a8a56",
            "6ec221eb53a94445b924d83be2592398",
            "ae9bca88fb07415b8a42da3cdc107171",
            "af851974e3e74096946643f6748e39fb",
            "7c1437b4d62e4c23b47b022b6a7fd5f1",
            "af20df649a944c9f865c5ae12cf53e05",
            "bc3f462a2bb245a3ade25dc5f5419a2a",
            "0716c15178014af19094381e5a17a0dd",
            "1eb2020f183647fdbb77a308afeb59cd",
            "65b64c7e4a5b46049b5858ad6a46dd95",
            "5541d7fe45b545cf8b2d64d26e062fb2",
            "eeaafebe54f442d9858388a9eef30ded",
            "7427985a72b048ca9667566676dcdf24",
            "9e1f22c0b47a4965b9977031f021f06d"
          ]
        },
        "id": "1YyQOpUfNE4Q",
        "outputId": "6a2349f9-3b2f-4258-ff38-243237e78c25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Balance Sheet Dataset (Expert A) ---\n",
            "{'question': 'Cash and cash equivalents assets of 2024?', 'answer': '$ 1,553 million.'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13479c6ab9804ac08533ff00a3ec1bd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af851974e3e74096946643f6748e39fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/66 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Assuming qa_documents is defined as before (with list of tuples)\n",
        "\n",
        "# --- Data Preparation ---\n",
        "balance_sheet_q = []\n",
        "balance_sheet_a = []\n",
        "income_statement_q = []\n",
        "income_statement_a = []\n",
        "\n",
        "# Iterate and populate separate lists for questions and answers\n",
        "for key, qa_list_of_tuples in qa_documents.items():\n",
        "    for question,answer  in qa_list_of_tuples:\n",
        "        if 'Balance Sheet' in key:\n",
        "            balance_sheet_q.append(question)\n",
        "            balance_sheet_a.append(answer)\n",
        "        elif 'Income Statement' in key:\n",
        "            income_statement_q.append(question)\n",
        "            income_statement_a.append(answer)\n",
        "\n",
        "# Create DataFrames with separate columns\n",
        "df_balance_sheet = pd.DataFrame({'question': balance_sheet_q, 'answer': balance_sheet_a})\n",
        "df_income_statement = pd.DataFrame({'question': income_statement_q, 'answer': income_statement_a})\n",
        "\n",
        "# Create Hugging Face Datasets\n",
        "balance_sheet_dataset = Dataset.from_pandas(df_balance_sheet)\n",
        "income_statement_dataset = Dataset.from_pandas(df_income_statement)\n",
        "\n",
        "print(\"--- Balance Sheet Dataset (Expert A) ---\")\n",
        "print(balance_sheet_dataset[0])\n",
        "\n",
        "\n",
        "# --- Corrected Preprocessing Function ---\n",
        "# This is the most critical change.\n",
        "def preprocess_seq2seq(examples):\n",
        "    # Tokenize the questions (inputs)\n",
        "    model_inputs = tokenizer(examples['question'], max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize the answers (labels)\n",
        "    labels = tokenizer(text_target=examples['answer'], max_length=50, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # The 'labels' field is what the model will learn to predict\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the new preprocessing function\n",
        "# Assumes 'tokenizer' is already loaded\n",
        "tokenized_balance_sheet_dataset = balance_sheet_dataset.map(preprocess_seq2seq, batched=True)\n",
        "tokenized_income_statement_dataset = income_statement_dataset.map(preprocess_seq2seq, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6sP4_0ZOvbW"
      },
      "source": [
        "##### Step 2: Train the Two Expert LoRA Adapters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "D19r7mB1RtGe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dir_balance_sheet = './lora_expert_balance_sheet'\n",
        "dir_income_statement = './lora_expert_income_statement'\n",
        "\n",
        "if os.path.exists(dir_balance_sheet):\n",
        "    shutil.rmtree(dir_balance_sheet)\n",
        "    print(f\"Deleted old directory: {dir_balance_sheet}\")\n",
        "\n",
        "if os.path.exists(dir_income_statement):\n",
        "    shutil.rmtree(dir_income_statement)\n",
        "    print(f\"Deleted old directory: {dir_income_statement}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "oLfjbaFROxHW",
        "outputId": "90739814-7265-4a0a-a302-e9add5ec6990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting INTENSIVE Training for Expert A (Balance Sheet) ---\n",
            "trainable params: 3,538,944 || all params: 251,116,800 || trainable%: 1.4093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2223498024.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  balance_sheet_trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2600' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2600/2600 09:27, Epoch 200/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.859700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.247000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.193900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.164500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert A (Balance Sheet) adapter saved.\n",
            "\n",
            "--- Starting INTENSIVE Training for Expert B (Income Statement) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2223498024.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  income_statement_trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1677' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1677/3400 05:12 < 05:21, 5.36 it/s, Epoch 98.59/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.374500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.247300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.175100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3400/3400 10:34, Epoch 200/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.374500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.247300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.175100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.142900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.126700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.116000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert B (Income Statement) adapter saved.\n"
          ]
        }
      ],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# --- Reusable Setup ---\n",
        "model_name = \"google/flan-t5-base\"\n",
        "# Assumes 'tokenizer' is loaded from data prep step\n",
        "\n",
        "# We give the model more capacity to learn the facts.\n",
        "lora_config = LoraConfig(\n",
        "    r=32,  # <-- INCREASED RANK from 16 to 32\n",
        "    lora_alpha=64,  # <-- INCREASED ALPHA from 32 to 64 (common practice is 2*r)\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n",
        "\n",
        "# --- Train Expert A (Balance Sheet) ---\n",
        "print(\"\\n--- Starting INTENSIVE Training for Expert A (Balance Sheet) ---\")\n",
        "balance_sheet_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "balance_sheet_peft_model = get_peft_model(balance_sheet_model, lora_config)\n",
        "balance_sheet_peft_model.print_trainable_parameters()\n",
        "\n",
        "balance_sheet_training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./lora_expert_balance_sheet\",\n",
        "    num_train_epochs=200,\n",
        "    learning_rate=1e-4,  # <-- Adjusted Learning Rate\n",
        "    per_device_train_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"cosine\",  # <-- Added a learning rate scheduler for stability\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "balance_sheet_trainer = Seq2SeqTrainer(\n",
        "    model=balance_sheet_peft_model,\n",
        "    args=balance_sheet_training_args,\n",
        "    train_dataset=tokenized_balance_sheet_dataset,  # Assumes this is correctly loaded\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "balance_sheet_trainer.train()\n",
        "balance_sheet_trainer.model.save_pretrained(\"./lora_expert_balance_sheet\")\n",
        "print(\"Expert A (Balance Sheet) adapter saved.\")\n",
        "\n",
        "\n",
        "# --- Train Expert B (Income Statement) ---\n",
        "print(\"\\n--- Starting INTENSIVE Training for Expert B (Income Statement) ---\")\n",
        "income_statement_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "income_statement_peft_model = get_peft_model(income_statement_model, lora_config)\n",
        "\n",
        "# Use the same aggressive arguments for the second expert\n",
        "income_statement_training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./lora_expert_income_statement\",\n",
        "    num_train_epochs=200,\n",
        "    learning_rate=1e-4,  # <-- Adjusted Learning Rate\n",
        "    per_device_train_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"cosine\",  # <-- Added a learning rate scheduler\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "income_statement_trainer = Seq2SeqTrainer(\n",
        "    model=income_statement_peft_model,\n",
        "    args=income_statement_training_args,\n",
        "    train_dataset=tokenized_income_statement_dataset,  # Assumes this is correctly loaded\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "income_statement_trainer.train()\n",
        "income_statement_trainer.model.save_pretrained(\"./lora_expert_income_statement\")\n",
        "print(\"Expert B (Income Statement) adapter saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA_x_VToPDQB"
      },
      "source": [
        "##### Step 3: Implement the Router and Perform Inference\n",
        "\n",
        "In our implementation, we have created a system-level Mixture-of-Experts (MoE). Instead of a single monolithic model, we use two smaller, specialized \"expert\" models, each fine-tuned on a distinct subset of financial dataone for the Balance Sheet and one for the Income Statement.\n",
        "Our route_to_financial_expert function serves as the gating network or router. This critical component analyzes the user's question and intelligently directs it to the appropriate expert, ensuring that the query is handled by the model with the most relevant training for that specific domain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O2do9ZpPFJr",
        "outputId": "2e8e6cbb-ac06-420a-df6d-bfe2db7ef570"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Testing the Correctly Trained Expert System ---\n",
            "Routing to... Expert 'BALANCE_SHEET'\n",
            "Q: Total liabilities of 2023?\n",
            "A: ('$ 17,026 million.', 0.31064701080322266, 0.9783398509025574)\n",
            "\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Q: Cost of services of 2024?\n",
            "A: ('$ 17,026 million.', 0.27557992935180664, 0.9995242357254028)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- 1. The Financial Router ---\n",
        "def route_to_financial_expert(question):\n",
        "    q_lower = question.lower()\n",
        "    if 'assets' in q_lower or 'liabilities' in q_lower:\n",
        "        return 'balance_sheet'\n",
        "    return 'income_statement'\n",
        "\n",
        "\n",
        "# --- 2. Load Base + Experts ---\n",
        "model_name = \"google/flan-t5-base\"\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "expert_balance_sheet = PeftModel.from_pretrained(base_model, \"./lora_expert_balance_sheet\")\n",
        "expert_income_statement = PeftModel.from_pretrained(base_model, \"./lora_expert_income_statement\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "expert_balance_sheet.to(device)\n",
        "expert_income_statement.to(device)\n",
        "\n",
        "\n",
        "# === 3. INFERENCE FUNCTION ===\n",
        "def query_finance_system_finetune(question):\n",
        "    expert_type = route_to_financial_expert(question)\n",
        "    print(f\"Routing to... Expert '{expert_type.upper()}'\")\n",
        "\n",
        "    model_to_use = expert_balance_sheet if expert_type == 'balance_sheet' else expert_income_statement\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Measure latency\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        outputs = model_to_use.generate(**inputs, max_new_tokens=50, output_scores=True, return_dict_in_generate=True)\n",
        "    latency = time.time() - start_time\n",
        "\n",
        "    # Decode text\n",
        "    answer = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "    # --- Confidence estimation ---\n",
        "    # Take first token probability as a simple proxy\n",
        "    if hasattr(outputs, \"scores\") and len(outputs.scores) > 0:\n",
        "        probs = F.softmax(outputs.scores[0], dim=-1)\n",
        "        first_token_id = outputs.sequences[0][1].item()  # token after <s>\n",
        "        confidence = probs[0, first_token_id].item()\n",
        "    else:\n",
        "        confidence = 0.0\n",
        "\n",
        "    return answer, latency, confidence\n",
        "\n",
        "\n",
        "# --- 4. Test the System ---\n",
        "print(\"\\n--- Testing the Correctly Trained Expert System ---\")\n",
        "\n",
        "question1 = \"Total liabilities of 2023?\"\n",
        "answer1 = query_finance_system_finetune(question1)\n",
        "print(f\"Q: {question1}\\nA: {answer1}\\n\")\n",
        "\n",
        "question2 = \"Cost of services of 2024?\"\n",
        "answer2 = query_finance_system_finetune(question2)\n",
        "print(f\"Q: {question2}\\nA: {answer2}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE-l4hiAjZpS"
      },
      "source": [
        "#### 3.6 Guardrail Implementation\n",
        "\n",
        "Input side - we are validating the input query to filter out irrelevant or harmful inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZVu4V5ujYf3",
        "outputId": "d242d63f-ec73-4f8d-e717-12aab3a32d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Routing to... Expert 'BALANCE_SHEET'\n",
            "Q: Assets of 2024?\n",
            "A: ('$ 16,221 million.', 0.2823517322540283, 0.987553596496582)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(True, 'Query is valid.')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "question = \"Assets of 2024?\"\n",
        "answer2 = query_finance_system_finetune(question)\n",
        "print(f\"Q: {question}\\nA: {answer2}\\n\")\n",
        "\n",
        "validate_query(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6ndTvKalzmc"
      },
      "source": [
        "3.7 Interface Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b1cCArchl0fK"
      },
      "outputs": [],
      "source": [
        "# implemented at the bottom of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLmAh5RHEOja"
      },
      "source": [
        "### 4. Testing, Evaluation & Comparison\n",
        "#### 4.1 Test Questions\n",
        "\n",
        "For both systems, ask three official questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UhlJVSREOja",
        "outputId": "4bb73302-2c82-4226-8c66-6918beae48a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant, high-confidence\n",
            "   Question: What was the total revenue in 2024?\n",
            "RAG System:\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "   Result: ('$ 16, 052 million', 0.8741888999938965, 0.5615305304527283)\n",
            "Fine-Tuned System:\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "   Result: ('$ 17,026 million.', 1.2007906436920166, 0.9929532408714294)\n",
            "Relevant, low-confidence\n",
            "   Question: What was the year-over-year (reported) revenue change for Kyndryl in fiscal year 2024 versus fiscal year 2023?\n",
            "RAG System:\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "   Result: ('$ 16, 052 million', 0.9512648582458496, 0.4123569428920746)\n",
            "Fine-Tuned System:\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "   Result: ('229.2 million.', 0.7766199111938477, 0.17903085052967072)\n",
            "Irrelevant\n",
            "   Question: What is the recipes of cookie?\n",
            "RAG System:\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "   Result: ('a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a : a :', 8.563113689422607, 7.581030914138864e-09)\n",
            "Fine-Tuned System:\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "   Result: ('sour', 0.5433776378631592, 0.20131638646125793)\n"
          ]
        }
      ],
      "source": [
        "test_questions = {\n",
        "    \"Relevant, high-confidence\": \"What was the total revenue in 2024?\",\n",
        "    \"Relevant, low-confidence\": \"What was the year-over-year (reported) revenue change for Kyndryl in fiscal year 2024 versus fiscal year 2023?\",\n",
        "    \"Irrelevant\": \"What is the recipes of cookie?\",\n",
        "}\n",
        "\n",
        "for category, test_question in test_questions.items():\n",
        "    print(f\"{category}\")\n",
        "    print(f\"   Question: {test_question}\")\n",
        "    print(\"RAG System:\")\n",
        "    result = query_finance_system_rag(test_question)\n",
        "    print(f\"   Result: {result}\")\n",
        "    print(\"Fine-Tuned System:\")\n",
        "    result = query_finance_system_finetune(test_question)\n",
        "    print(f\"   Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqVxBPjEOja"
      },
      "source": [
        "#### 4.2 & 4.3 Extended Evaluation with results\n",
        "\n",
        "Evaluate both systems on at least 10 different financial questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftpe90Z9EOja",
        "outputId": "30874c90-0049-4bed-d720-12b6bbec42e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Routing to... Expert 'BALANCE_SHEET'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 5 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 6 unique chunks.\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "|    | Method    | Query                                                              | Response             | Ground Truth       |   Accuracy |   Latency (s) |   Confidence |\n",
            "|---:|:----------|:-------------------------------------------------------------------|:---------------------|:-------------------|-----------:|--------------:|-------------:|\n",
            "|  0 | RAG       | What were the total revenues in fiscal 2024?                       | $ 16, 052 million    | $ 16,052 million.  |      0.977 |         0.362 |    0.624393  |\n",
            "|  1 | Fine-Tune | What were the total revenues in fiscal 2024?                       | $ 17,026 million.    | $ 16,052 million.  |      0.881 |         0.57  |    0.992085  |\n",
            "|  2 | RAG       | What were the total score in fiscal 2023?                          | $ ( 175 ) million    | Not applicable     |      0.14  |         0.632 |    0.0169149 |\n",
            "|  3 | Fine-Tune | What were the total score in fiscal 2023?                          | $ 17,026 million.    | Not applicable     |      0.061 |         0.407 |    0.60399   |\n",
            "|  4 | RAG       | Cost of services of 2024?                                          | 13, 189 million      | $ 13,189 million.  |      0.87  |         0.373 |    0.732187  |\n",
            "|  5 | Fine-Tune | Cost of services of 2024?                                          | $ 17,026 million.    | $ 13,189 million.  |      0.693 |         0.453 |    0.999524  |\n",
            "|  6 | RAG       | What was the cost of services in fiscal 2023?                      | $ 14, 498 million    | $ 14,498 million.  |      0.98  |         0.507 |    0.171587  |\n",
            "|  7 | Fine-Tune | What was the cost of services in fiscal 2023?                      | $ 16,221 million.    | $ 14,498 million.  |      0.655 |         0.727 |    0.989354  |\n",
            "|  8 | RAG       | What was the net income (loss) reported in fiscal 2024?            | $ ( 1, 374 ) million | $ (340) million.   |      0.712 |         0.692 |    0.39201   |\n",
            "|  9 | Fine-Tune | What was the net income (loss) reported in fiscal 2024?            | $ (1,344) million.   | $ (340) million.   |      0.817 |         1.172 |    0.996776  |\n",
            "| 10 | RAG       | What was the net income (loss) reported in fiscal 2023?            | $ ( 1, 374 ) million | $ (1,374) million. |      0.98  |         1.714 |    0.184213  |\n",
            "| 11 | Fine-Tune | What was the net income (loss) reported in fiscal 2023?            | $ (1,344) million.   | $ (1,374) million. |      0.862 |         0.99  |    0.997744  |\n",
            "| 12 | RAG       | Cookie recipe?                                                     | (iii).               | Not Applicable     |      0.326 |         0.313 |    0.005674  |\n",
            "| 13 | Fine-Tune | Cookie recipe?                                                     | a sour               | Not Applicable     |      0.114 |         0.374 |    0.204509  |\n",
            "| 14 | RAG       | How much were the total liabilities in fiscal 2023?                | $ 10, 002 million    | $ 10,002 million.  |      0.978 |         0.354 |    0.17307   |\n",
            "| 15 | Fine-Tune | How much were the total liabilities in fiscal 2023?                | $ 17,026 million.    | $ 10,002 million.  |      0.712 |         0.207 |    0.975508  |\n",
            "| 16 | RAG       | What were the cash and cash equivalents at the end of fiscal 2024? | $ 1, 553 million     | $ 1,553 million.   |      0.971 |         0.192 |    0.851834  |\n",
            "| 17 | Fine-Tune | What were the cash and cash equivalents at the end of fiscal 2024? | $ 17,026 million.    | $ 1,553 million.   |      0.711 |         0.201 |    0.734607  |\n",
            "| 18 | RAG       | What were the cash and cash equivalents at the end of fiscal 2023? | $ 1, 847 million     | $ 1,847 million.   |      0.968 |         0.194 |    0.815999  |\n",
            "| 19 | Fine-Tune | What were the cash and cash equivalents at the end of fiscal 2023? | $ 17,026 million.    | $ 1,847 million.   |      0.732 |         0.209 |    0.793527  |\n",
            "Evaluated both RAG and Fine Tuning.\n"
          ]
        }
      ],
      "source": [
        "evaluate(test_questions_10, True, True)\n",
        "print('Evaluated both RAG and Fine Tuning.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdWDZ6EBMXKs"
      },
      "source": [
        "RAG consistently gave more factually accurate answers aligned with the financial ground truth, showing higher accuracy across most queries but with lower confidence scores.\n",
        "Fine-tuning on small number of data produced fluent outputs with very high confidence, but it often overfit to repeated patterns (e.g., $17,026 million), leading to weaker factual reliability compared to RAG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQfkRKzBEOja"
      },
      "source": [
        "### 4.4 Analysis\n",
        "\n",
        "The amount of data is too less for fine-tuning the model. This financial data helps RAG system excel with the grounding facts.\n",
        "\n",
        "#### RAG (Retrieval-Augmented Generation)\n",
        "\n",
        "Pros\n",
        "\n",
        "Adaptability  Easy to update answers when new 10-Ks or balance sheets come out.\n",
        "\n",
        "Factual grounding  Pulls numbers directly from source documents, reducing hallucinations.\n",
        "\n",
        "Cons\n",
        "\n",
        "Retrieval errors  With noisy queries, it may fetch irrelevant sections, hurting accuracy.\n",
        "\n",
        "Latency & complexity  Needs a search index + retriever model, which adds infra overhead.\n",
        "\n",
        "#### Fine-Tuning (with 50 Q&A)\n",
        "\n",
        "Pros\n",
        "\n",
        "Fluency  Model learns consistent, natural financial reporting style.\n",
        "\n",
        "Efficiency  At inference, no retrieval step, so answers are faster once trained.\n",
        "\n",
        "Cons (especially with just 50 Q&A)\n",
        "\n",
        "Overfitting  The model memorizes those 50 examples, failing to generalize to new financial phrasing.\n",
        "\n",
        "Catastrophic forgetting  May lose some general language ability since so little data is steering it.\n",
        "\n",
        "#### Robustness to Irrelevant Queries\n",
        "\n",
        "RAG: Safer  it can say no relevant context found, though still depends on retriever quality.\n",
        "\n",
        "Fine-Tuning (50 Q&A): Riskier  with so little data, the model will often hallucinate plausible but wrong answers.\n",
        "\n",
        "#### Practical Trade-offs\n",
        "\n",
        "RAG:\n",
        " Cheaper to maintain knowledge freshness.\n",
        " Needs extra infra (vector DB, retriever).\n",
        "\n",
        "Fine-Tuning (50 Q&A):\n",
        " Simpler runtime (just the model).\n",
        " Very weak generalization with so little data; retraining required when new reports come.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JNPn3zXF4BT"
      },
      "source": [
        "## UI Implementation using Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "n5beYWR1F8Ye",
        "outputId": "f9aa5881-d4fb-45a7-e1d8-0096c1321fc0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "# ---- Router to your existing backends ----\n",
        "\n",
        "\n",
        "def _run_backend(question: str, mode: str) -> str:\n",
        "    q = (question or \"\").strip()\n",
        "    if not q:\n",
        "        return \"Please enter a question.\"\n",
        "\n",
        "    # Optional guardrail if defined earlier\n",
        "    try:\n",
        "        is_valid, reason = validate_query(q)\n",
        "        if not is_valid:\n",
        "            return f\"[Guardrail] {reason}\"\n",
        "    except NameError:\n",
        "        pass\n",
        "    if mode == \"RAG\":\n",
        "        return query_finance_system_rag(q)\n",
        "    else:\n",
        "        return query_finance_system_finetune(q)\n",
        "\n",
        "\n",
        "# ---- Main handler ----\n",
        "def answer_and_log(question: str, mode: str, history: list):\n",
        "    \"\"\"\n",
        "    Returns: answer_text, updated_history, chatbot_pairs, history_df\n",
        "    \"\"\"\n",
        "    answer_text = _run_backend(question, mode)\n",
        "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    entry = {\n",
        "        \"time\": ts,\n",
        "        \"method\": mode,\n",
        "        \"question\": (question or \"\").strip(),\n",
        "        \"answer\": answer_text,\n",
        "    }\n",
        "    history = (history or []) + [entry]\n",
        "    chatbot_pairs = [(h[\"question\"], f\"[{h['method']}] {h['answer']}\") for h in history]\n",
        "    hist_df = pd.DataFrame(history, columns=[\"time\", \"method\", \"question\", \"answer\"])\n",
        "    return f\"[{mode}] {answer_text}\", history, chatbot_pairs, hist_df\n",
        "\n",
        "\n",
        "def clear_history():\n",
        "    return \"\", [], [], pd.DataFrame(columns=[\"time\", \"method\", \"question\", \"answer\"])\n",
        "\n",
        "\n",
        "# ---- UI (Blocks) ----\n",
        "with gr.Blocks(title=\"Financial QA  RAG vs Fine-Tuned\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"## Financial QA  RAG vs Fine-Tuned\\nAsk a question about the Kyndryl financial reports and see history below.\"\n",
        "    )\n",
        "    state_history = gr.State([])\n",
        "    with gr.Row():\n",
        "\n",
        "        with gr.Column(scale=5):\n",
        "\n",
        "            question_in = gr.Textbox(\n",
        "                label=\"Question\",\n",
        "                placeholder=\"e.g., What were the total revenues in fiscal 2024?\",\n",
        "                lines=2,\n",
        "            )\n",
        "\n",
        "            mode_in = gr.Radio(\n",
        "                choices=[\"RAG\", \"Fine-Tune\"],\n",
        "                value=\"RAG\",\n",
        "                label=\"Method\",\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                ask_btn = gr.Button(\"Answer\", variant=\"primary\")\n",
        "                clear_btn = gr.Button(\"Clear History\")\n",
        "\n",
        "        with gr.Column(scale=5):\n",
        "            answer_out = gr.Markdown(label=\"Answer\")\n",
        "            chat_out = gr.Chatbot(\n",
        "                label=\"Q/A History (Chat view)\", bubble_full_width=False\n",
        "            )\n",
        "            table_out = gr.Dataframe(label=\"History (Table view)\", interactive=False)\n",
        "\n",
        "    # Button wiring\n",
        "    ask_btn.click(\n",
        "        fn=answer_and_log,\n",
        "        inputs=[question_in, mode_in, state_history],\n",
        "        outputs=[answer_out, state_history, chat_out, table_out],\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_history,\n",
        "        inputs=None,\n",
        "        outputs=[answer_out, state_history, chat_out, table_out],\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=int(os.getenv(\"PORT\", 7861)),\n",
        "        # share=True,  # enable locally if you want a public gradio.live link\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0716c15178014af19094381e5a17a0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fb5ced3680467f8f868dc368fbeccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c69a1b5abc5488a8e68ff504d7c0743": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106e9e2a6f434411ac746d2333880c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d2b200ba564f25b136c9bac0fd8dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f49919dd21649149f6f6660321fe803",
            "placeholder": "",
            "style": "IPY_MODEL_08fb5ced3680467f8f868dc368fbeccf",
            "value": "118/118[00:00&lt;00:00,2145.07examples/s]"
          }
        },
        "13479c6ab9804ac08533ff00a3ec1bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33bde37efc7243399c5869831fe33456",
              "IPY_MODEL_729e58e33e7345599e171848064e233a",
              "IPY_MODEL_bf962fd6614849c48c42cc4cf92def0a"
            ],
            "layout": "IPY_MODEL_b380ba3e952144c9ad1d6ca8fca7af17"
          }
        },
        "1eb2020f183647fdbb77a308afeb59cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2393442f5e6c45caa20a6df4e745d951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2d1cf23642848ac8bd9784a92e034f7",
            "placeholder": "",
            "style": "IPY_MODEL_106e9e2a6f434411ac746d2333880c4b",
            "value": "Map:100%"
          }
        },
        "327145d1365b4a74add34098ce9ae446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bde37efc7243399c5869831fe33456": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2674110b45949e98c31b06598367db4",
            "placeholder": "",
            "style": "IPY_MODEL_c8b61ef8dead4ef8b43410b7fbf34bf2",
            "value": "Map:100%"
          }
        },
        "44b015d67e4f4d62bab0aa12f9c1dd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5541d7fe45b545cf8b2d64d26e062fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b64c7e4a5b46049b5858ad6a46dd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68fc5d7d6958449b82414901d8e2a930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3b9ec8145f4fa09f9b40e0162a7dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faff4591f0ab45108a48603e7d2be814",
              "IPY_MODEL_6deb5da94ab54c8386a4d86bb6a5dfea",
              "IPY_MODEL_870d4def46f64cda83477152afb9bb32"
            ],
            "layout": "IPY_MODEL_0c69a1b5abc5488a8e68ff504d7c0743"
          }
        },
        "6deb5da94ab54c8386a4d86bb6a5dfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68fc5d7d6958449b82414901d8e2a930",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79a93d0964d14a18a494bc951cc2bbde",
            "value": 8
          }
        },
        "6ec221eb53a94445b924d83be2592398": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729e58e33e7345599e171848064e233a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b015d67e4f4d62bab0aa12f9c1dd3c",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad430b45baa2401390544eced22a8a56",
            "value": 52
          }
        },
        "7427985a72b048ca9667566676dcdf24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a93d0964d14a18a494bc951cc2bbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c1437b4d62e4c23b47b022b6a7fd5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eb2020f183647fdbb77a308afeb59cd",
            "placeholder": "",
            "style": "IPY_MODEL_65b64c7e4a5b46049b5858ad6a46dd95",
            "value": "Map:100%"
          }
        },
        "870d4def46f64cda83477152afb9bb32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327145d1365b4a74add34098ce9ae446",
            "placeholder": "",
            "style": "IPY_MODEL_d8617592a52c4854b37da5fdb50daa97",
            "value": "8/8[00:00&lt;00:00,19.15it/s]"
          }
        },
        "89f9112a1bee481484acc814bbeafb5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d26812b50324348b2681c017a99ed71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f9112a1bee481484acc814bbeafb5d",
            "max": 118,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d839c92368ed44168ac947f8bba2d4de",
            "value": 118
          }
        },
        "9e1f22c0b47a4965b9977031f021f06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f49919dd21649149f6f6660321fe803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2674110b45949e98c31b06598367db4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99d88f6aa244195a3ba75bdbb7c4b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad430b45baa2401390544eced22a8a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae9bca88fb07415b8a42da3cdc107171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af20df649a944c9f865c5ae12cf53e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5541d7fe45b545cf8b2d64d26e062fb2",
            "max": 66,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeaafebe54f442d9858388a9eef30ded",
            "value": 66
          }
        },
        "af851974e3e74096946643f6748e39fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1437b4d62e4c23b47b022b6a7fd5f1",
              "IPY_MODEL_af20df649a944c9f865c5ae12cf53e05",
              "IPY_MODEL_bc3f462a2bb245a3ade25dc5f5419a2a"
            ],
            "layout": "IPY_MODEL_0716c15178014af19094381e5a17a0dd"
          }
        },
        "af9b89e81ef34515aa4056b0d4e5a391": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d1cf23642848ac8bd9784a92e034f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b380ba3e952144c9ad1d6ca8fca7af17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3f462a2bb245a3ade25dc5f5419a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7427985a72b048ca9667566676dcdf24",
            "placeholder": "",
            "style": "IPY_MODEL_9e1f22c0b47a4965b9977031f021f06d",
            "value": "66/66[00:00&lt;00:00,915.36examples/s]"
          }
        },
        "bf962fd6614849c48c42cc4cf92def0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec221eb53a94445b924d83be2592398",
            "placeholder": "",
            "style": "IPY_MODEL_ae9bca88fb07415b8a42da3cdc107171",
            "value": "52/52[00:00&lt;00:00,851.79examples/s]"
          }
        },
        "c8b61ef8dead4ef8b43410b7fbf34bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d16b71bebf344c3d85349a681fa26080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d839c92368ed44168ac947f8bba2d4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8617592a52c4854b37da5fdb50daa97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea3cf65453be471d8acfd6e40accaba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2393442f5e6c45caa20a6df4e745d951",
              "IPY_MODEL_9d26812b50324348b2681c017a99ed71",
              "IPY_MODEL_10d2b200ba564f25b136c9bac0fd8dd5"
            ],
            "layout": "IPY_MODEL_af9b89e81ef34515aa4056b0d4e5a391"
          }
        },
        "eeaafebe54f442d9858388a9eef30ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faff4591f0ab45108a48603e7d2be814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99d88f6aa244195a3ba75bdbb7c4b3b",
            "placeholder": "",
            "style": "IPY_MODEL_d16b71bebf344c3d85349a681fa26080",
            "value": "Batches:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
